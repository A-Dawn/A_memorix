"""
çŸ¥è¯†æŸ¥è¯¢Toolç»„ä»¶

æä¾›LLMå¯è°ƒç”¨çš„çŸ¥è¯†æŸ¥è¯¢å·¥å…·ã€‚
"""

import time
from typing import Any, List, Tuple, Optional, Dict
from pathlib import Path

from src.common.logger import get_logger
from src.plugin_system.base.base_tool import BaseTool
from src.plugin_system.base.component_types import ToolParamType
from src.chat.message_receive.chat_stream import ChatStream

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ...core import (
    DualPathRetriever,
    RetrievalStrategy,
    DualPathRetrieverConfig,
    DynamicThresholdFilter,
    ThresholdMethod,
    ThresholdConfig,
)

logger = get_logger("A_Memorix.KnowledgeQueryTool")


class KnowledgeQueryTool(BaseTool):
    """çŸ¥è¯†æŸ¥è¯¢Tool

    åŠŸèƒ½ï¼š
    - åŒè·¯æ£€ç´¢æŸ¥è¯¢
    - å®ä½“æŸ¥è¯¢
    - å…³ç³»æŸ¥è¯¢
    - ç»Ÿè®¡ä¿¡æ¯
    - LLMå¯ç›´æ¥è°ƒç”¨
    """

    # ToolåŸºæœ¬ä¿¡æ¯
    name = "knowledge_query"
    description = "æŸ¥è¯¢A_MemorixçŸ¥è¯†åº“ï¼Œæ”¯æŒæ£€ç´¢ã€å®ä½“æŸ¥è¯¢ã€å…³ç³»æŸ¥è¯¢å’Œç»Ÿè®¡ä¿¡æ¯"

    # Toolå‚æ•°å®šä¹‰
    parameters: List[Tuple[str, ToolParamType, str, bool, List[str] | None]] = [
        (
            "query_type",
            ToolParamType.STRING,
            "æŸ¥è¯¢ç±»å‹ï¼šsearch(æ£€ç´¢)ã€entity(å®ä½“)ã€relation(å…³ç³»)ã€stats(ç»Ÿè®¡)",
            True,
            ["search", "entity", "relation", "stats"],
        ),
        (
            "query",
            ToolParamType.STRING,
            "æŸ¥è¯¢å†…å®¹ï¼ˆæ£€ç´¢æ–‡æœ¬/å®ä½“åç§°/å…³ç³»è§„æ ¼ï¼‰ï¼Œstatsæ¨¡å¼ä¸éœ€è¦",
            False,
            None,
        ),
        (
            "top_k",
            ToolParamType.INTEGER,
            "è¿”å›ç»“æœæ•°é‡ï¼ˆä»…searchæ¨¡å¼ï¼‰",
            False,
            None,
        ),
        (
            "use_threshold",
            ToolParamType.BOOLEAN,
            "æ˜¯å¦ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è¿‡æ»¤ï¼ˆä»…searchæ¨¡å¼ï¼‰",
            False,
            None,
        ),
    ]

    # LLMå¯ç”¨
    available_for_llm = True

    def __init__(self, plugin_config: Optional[dict] = None, chat_stream: Optional["ChatStream"] = None):
        """åˆå§‹åŒ–çŸ¥è¯†æŸ¥è¯¢Tool"""
        super().__init__(plugin_config, chat_stream)

        # è·å–å­˜å‚¨å®ä¾‹
        self.vector_store = self.plugin_config.get("vector_store")
        self.graph_store = self.plugin_config.get("graph_store")
        self.metadata_store = self.plugin_config.get("metadata_store")
        self.embedding_manager = self.plugin_config.get("embedding_manager")

        # åˆå§‹åŒ–æ£€ç´¢å™¨
        self.retriever: Optional[DualPathRetriever] = None
        self.threshold_filter: Optional[DynamicThresholdFilter] = None

        # è®¾ç½®æ—¥å¿—å‰ç¼€
        chat_id = self.chat_id if self.chat_id else "unknown"
        self.log_prefix = f"[KnowledgeQueryTool-{chat_id}]"

        # åˆå§‹åŒ–ç»„ä»¶
        self._initialize_components()

    @property
    def debug_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è°ƒè¯•æ¨¡å¼"""
        advanced = self.plugin_config.get("advanced", {})
        if isinstance(advanced, dict):
            return advanced.get("debug", False)
        return self.plugin_config.get("debug", False)

    def _initialize_components(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å’Œè¿‡æ»¤ç»„ä»¶"""
        try:
            # æ£€æŸ¥å­˜å‚¨æ˜¯å¦å¯ç”¨ (ä¼˜å…ˆä»é…ç½®è·å–ï¼Œå…œåº•ä»æ’ä»¶å®ä¾‹è·å–)
            vector_store = self.vector_store
            graph_store = self.graph_store
            metadata_store = self.metadata_store
            embedding_manager = self.embedding_manager

            # å…œåº•é€»è¾‘ï¼šå¦‚æœé…ç½®ä¸­æ²¡æœ‰å­˜å‚¨å®ä¾‹ï¼Œå°è¯•ç›´æ¥ä»æ’ä»¶ç³»ç»Ÿè·å–
            # ä½¿ç”¨ is not None æ£€æŸ¥ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½å¸ƒå°”å€¼ä¸º False
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                from ...plugin import A_MemorixPlugin
                instances = A_MemorixPlugin.get_storage_instances()
                if instances:
                    vector_store = vector_store or instances.get("vector_store")
                    graph_store = graph_store or instances.get("graph_store")
                    metadata_store = metadata_store or instances.get("metadata_store")
                    embedding_manager = embedding_manager or instances.get("embedding_manager")
                    
                    # åŒæ­¥å›å®ä¾‹å±æ€§
                    self.vector_store = vector_store
                    self.graph_store = graph_store
                    self.metadata_store = metadata_store
                    self.embedding_manager = embedding_manager


            # æœ€ç»ˆæ£€æŸ¥ (ä½¿ç”¨ is not None è€Œéå¸ƒå°”å€¼ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½ä¸º False)
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                logger.warning(f"{self.log_prefix} å­˜å‚¨ç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–")
                return

            # åˆ›å»ºæ£€ç´¢å™¨é…ç½®
            config = DualPathRetrieverConfig(
                top_k_paragraphs=self.get_config("retrieval.top_k_paragraphs", 20),
                top_k_relations=self.get_config("retrieval.top_k_relations", 10),
                top_k_final=self.get_config("retrieval.top_k_final", 10),
                alpha=self.get_config("retrieval.alpha", 0.5),
                enable_ppr=self.get_config("retrieval.enable_ppr", True),
                ppr_alpha=self.get_config("retrieval.ppr_alpha", 0.85),
                enable_parallel=self.get_config("retrieval.enable_parallel", True),
                retrieval_strategy=RetrievalStrategy.DUAL_PATH,
            )

            # åˆ›å»ºæ£€ç´¢å™¨
            self.retriever = DualPathRetriever(
                vector_store=self.vector_store,
                graph_store=self.graph_store,
                metadata_store=self.metadata_store,
                embedding_manager=self.embedding_manager,
                config=config,
            )

            # åˆ›å»ºé˜ˆå€¼è¿‡æ»¤å™¨
            threshold_config = ThresholdConfig(
                method=ThresholdMethod.ADAPTIVE,
                min_threshold=self.get_config("threshold.min_threshold", 0.3),
                max_threshold=self.get_config("threshold.max_threshold", 0.95),
                percentile=self.get_config("threshold.percentile", 75.0),
                std_multiplier=self.get_config("threshold.std_multiplier", 1.5),
                min_results=self.get_config("threshold.min_results", 3),
                enable_auto_adjust=self.get_config("threshold.enable_auto_adjust", True),
            )

            self.threshold_filter = DynamicThresholdFilter(threshold_config)

            logger.info(f"{self.log_prefix} çŸ¥è¯†æŸ¥è¯¢Toolåˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"{self.log_prefix} ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")

    async def execute(self, function_args: dict[str, Any]) -> dict[str, Any]:
        """æ‰§è¡Œå·¥å…·å‡½æ•°ï¼ˆä¾›LLMè°ƒç”¨ï¼‰

        Args:
            function_args: å·¥å…·è°ƒç”¨å‚æ•°
                - query_type: æŸ¥è¯¢ç±»å‹
                - query: æŸ¥è¯¢å†…å®¹
                - top_k: è¿”å›ç»“æœæ•°é‡
                - use_threshold: æ˜¯å¦ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤

        Returns:
            dict: å·¥å…·æ‰§è¡Œç»“æœ
        """
        # æ£€æŸ¥ç»„ä»¶æ˜¯å¦åˆå§‹åŒ–
        if not self.retriever:
            return {
                "success": False,
                "error": "çŸ¥è¯†æŸ¥è¯¢Toolæœªåˆå§‹åŒ–",
                "content": "âŒ çŸ¥è¯†æŸ¥è¯¢Toolæœªåˆå§‹åŒ–",
                "results": [],
            }

        # è§£æå‚æ•°
        query_type = function_args.get("query_type", "search")
        query = function_args.get("query", "")
        top_k = function_args.get("top_k", 10)
        use_threshold = function_args.get("use_threshold", True)

        logger.info(
            f"{self.log_prefix} LLMè°ƒç”¨: query_type={query_type}, "
            f"query='{query}', top_k={top_k}"
        )

        if self.debug_enabled:
            logger.info(f"{self.log_prefix} [DEBUG] å·¥å…·å®Œæ•´å‚æ•°: {function_args}")

        try:
            # æ ¹æ®æŸ¥è¯¢ç±»å‹æ‰§è¡Œ
            if query_type == "search":
                result = await self._search(query, top_k, use_threshold)
            elif query_type == "entity":
                result = await self._query_entity(query)
            elif query_type == "relation":
                result = await self._query_relation(query)
            elif query_type == "stats":
                result = self._get_stats()
            else:
                result = {
                    "success": False,
                    "error": f"æœªçŸ¥çš„æŸ¥è¯¢ç±»å‹: {query_type}",
                    "content": f"âŒ æœªçŸ¥çš„æŸ¥è¯¢ç±»å‹: {query_type}",
                    "results": [],
                }

            return result

        except Exception as e:
            error_msg = f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
            logger.error(f"{self.log_prefix} {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "content": f"âŒ æŸ¥è¯¢å‘ç”Ÿé”™è¯¯: {error_msg}",
                "results": [],
            }

    async def direct_execute(
        self,
        query_type: str = "search",
        query: str = "",
        top_k: int = 10,
        use_threshold: bool = True,
    ) -> Dict[str, Any]:
        """ç›´æ¥æ‰§è¡Œå·¥å…·å‡½æ•°ï¼ˆä¾›æ’ä»¶è°ƒç”¨ï¼‰

        Args:
            query_type: æŸ¥è¯¢ç±»å‹
            query: æŸ¥è¯¢å†…å®¹
            top_k: è¿”å›ç»“æœæ•°é‡
            use_threshold: æ˜¯å¦ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤

        Returns:
            Dict: æ‰§è¡Œç»“æœ
        """
        function_args = {
            "query_type": query_type,
            "query": query,
            "top_k": top_k,
            "use_threshold": use_threshold,
        }

        return await self.execute(function_args)

    async def _search(
        self,
        query: str,
        top_k: int,
        use_threshold: bool,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ£€ç´¢æŸ¥è¯¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            use_threshold: æ˜¯å¦ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤

        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸
        """
        if not query:
            return {
                "success": False,
                "error": "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º",
                "content": "âš ï¸ æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º",
                "results": [],
            }

        start_time = time.time()

        # æ‰§è¡Œæ£€ç´¢ï¼ˆå¼‚æ­¥è°ƒç”¨ï¼‰
        results = await self.retriever.retrieve(query, top_k=top_k)

        # åº”ç”¨é˜ˆå€¼è¿‡æ»¤
        if use_threshold and self.threshold_filter:
            results = self.threshold_filter.filter(results)
            if self.debug_enabled:
                logger.info(f"{self.log_prefix} [DEBUG] è¿‡æ»¤åç»“æœæ•°é‡ (Tool): {len(results)}")

        elapsed = time.time() - start_time

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        try:
            for i, result in enumerate(results):
                # DEBUG: Check result type
                if self.debug_enabled:
                    logger.info(f"{self.log_prefix} Result {i} type: {type(result)}")
                    
                formatted_results.append({
                    "type": result.result_type,
                    "score": float(result.score),
                    "content": result.content,
                    "metadata": result.metadata,
                })
        except Exception as e:
            logger.error(f"{self.log_prefix} Error formatting results: {e}")
            raise

        # ç”Ÿæˆ content æ‘˜è¦
        if formatted_results:
            summary_lines = [f"æ‰¾åˆ° {len(formatted_results)} æ¡ç»“æœï¼š"]
            for i, res in enumerate(formatted_results[:5]):
                type_icon = "ğŸ“„" if res['type'] == 'paragraph' else "ğŸ”—"
                try:
                    summary_lines.append(f"{i+1}. {type_icon} {res.get('content', 'N/A')} ({res.get('score', 0.0):.2f})")
                except Exception as e:
                     logger.error(f"{self.log_prefix} Error generating summary for index {i}: {e}")
                     # Defensively continue
                     summary_lines.append(f"{i+1}. {type_icon} [Error accessing content] ({res.get('score', 0.0):.2f})")
                     
            content = "\n".join(summary_lines)
        else:
            content = "æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"

        return {
            "success": True,
            "query_type": "search",
            "query": query,
            "results": formatted_results,
            "count": len(formatted_results),
            "elapsed_ms": elapsed * 1000,
            "content": content,
        }

    async def _query_entity(self, entity_name: str) -> Dict[str, Any]:
        """æŸ¥è¯¢å®ä½“ä¿¡æ¯

        Args:
            entity_name: å®ä½“åç§°

        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸
        """
        if not entity_name:

            return {
                "success": False,
                "error": "å®ä½“åç§°ä¸èƒ½ä¸ºç©º",
                "content": "âš ï¸ å®ä½“åç§°ä¸èƒ½ä¸ºç©º",
                "results": [],
            }

        # æ£€æŸ¥å®ä½“æ˜¯å¦å­˜åœ¨
        if not self.graph_store.has_node(entity_name):

            return {
                "success": False,
                "error": f"å®ä½“ä¸å­˜åœ¨: {entity_name}",
                "content": f"âŒ å®ä½“ '{entity_name}' ä¸å­˜åœ¨",
                "results": [],
            }

        # è·å–é‚»å±…èŠ‚ç‚¹
        neighbors = self.graph_store.get_neighbors(entity_name)

        # è·å–ç›¸å…³æ®µè½
        paragraphs = self.metadata_store.get_paragraphs_by_entity(entity_name)

        # æ ¼å¼åŒ–æ®µè½
        formatted_paragraphs = [
            {
                "hash": para["hash"],
                "content": para["content"],
                "created_at": para.get("created_at"),
            }
            for para in paragraphs
        ]


        # ç”Ÿæˆ content æ‘˜è¦
        content_lines = [f"å®ä½“ '{entity_name}' ä¿¡æ¯ï¼š"]
        content_lines.append(f"- é‚»å±…èŠ‚ç‚¹ ({len(neighbors)}): {', '.join(neighbors[:10])}{'...' if len(neighbors)>10 else ''}")
        content_lines.append(f"- ç›¸å…³æ®µè½ ({len(paragraphs)}):")
        for i, para in enumerate(formatted_paragraphs[:3]):
             content_lines.append(f"  {i+1}. {para['content'][:50]}...")
        
        content = "\n".join(content_lines)

        return {
            "success": True,
            "query_type": "entity",
            "entity": entity_name,
            "neighbors": neighbors,
            "related_paragraphs": formatted_paragraphs,
            "neighbor_count": len(neighbors),
            "paragraph_count": len(paragraphs),
            "content": content,
        }

    async def _query_relation(self, relation_spec: str) -> Dict[str, Any]:
        """æŸ¥è¯¢å…³ç³»ä¿¡æ¯

        Args:
            relation_spec: å…³ç³»è§„æ ¼

        Returns:
            æŸ¥è¯¢ç»“æœå­—å…¸
        """
        if not relation_spec:

            return {
                "success": False,
                "error": "å…³ç³»è§„æ ¼ä¸èƒ½ä¸ºç©º",
                "content": "âš ï¸ å…³ç³»è§„æ ¼ä¸èƒ½ä¸ºç©º",
                "results": [],
            }

        # è§£æå…³ç³»è§„æ ¼
        if "|" in relation_spec:
            parts = relation_spec.split("|")
            if len(parts) < 2:
                return {
                    "success": False,
                    "error": "å…³ç³»æ ¼å¼é”™è¯¯",
                    "content": "âŒ å…³ç³»æ ¼å¼é”™è¯¯",
                    "results": [],
                }
            subject = parts[0].strip()
            predicate = parts[1].strip()
            obj = parts[2].strip() if len(parts) > 2 else None
        else:
            parts = relation_spec.split(maxsplit=1)
            if len(parts) < 2:
                return {
                    "success": False,
                    "error": "å…³ç³»æ ¼å¼é”™è¯¯",
                    "content": "âŒ å…³ç³»æ ¼å¼é”™è¯¯",
                    "results": [],
                }
            subject = parts[0].strip()
            predicate = parts[1].strip()
            obj = None

        # æŸ¥è¯¢å…³ç³»
        relations = self.metadata_store.get_relations(
            subject=subject if subject else None,
            predicate=predicate if predicate else None,
            object=obj if obj else None,
        )

        # æ ¼å¼åŒ–å…³ç³»
        formatted_relations = []
        for rel in relations:
            formatted_relations.append({
                "hash": rel["hash"],
                "subject": rel["subject"],
                "predicate": rel["predicate"],
                "object": rel["object"],  # æ•°æ®åº“åˆ—åå°±æ˜¯ 'object'
                "confidence": rel.get("confidence", 1.0),
            })


        # ç”Ÿæˆ content æ‘˜è¦
        if formatted_relations:
            lines = [f"æ‰¾åˆ° {len(formatted_relations)} æ¡å…³ç³»ï¼š"]
            for i, rel in enumerate(formatted_relations[:10]):
                lines.append(f"{i+1}. {rel['subject']} {rel['predicate']} {rel['object']}")
            content = "\n".join(lines)
        else:
            content = "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å…³ç³»ã€‚"

        return {
            "success": True,
            "query_type": "relation",
            "spec": {"subject": subject, "predicate": predicate, "object": obj},
            "results": formatted_relations,
            "count": len(formatted_relations),
            "content": content,
        }

    def _get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            "vector_store": {
                "num_vectors": self.vector_store.num_vectors if self.vector_store else 0,
                "dimension": self.vector_store.dimension if self.vector_store else 0,
            },
            "graph_store": {
                "num_nodes": self.graph_store.num_nodes if self.graph_store else 0,
                "num_edges": self.graph_store.num_edges if self.graph_store else 0,
            },
            "metadata_store": {
                "num_paragraphs": self.metadata_store.count_paragraphs() if self.metadata_store else 0,
                "num_relations": self.metadata_store.count_relations() if self.metadata_store else 0,
                "num_entities": self.metadata_store.count_entities() if self.metadata_store else 0,
            },
        }

        # Format a human-readable summary
        content = (
            f"ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯\n\n"
            f"ğŸ“¦ å‘é‡å­˜å‚¨:\n"
            f"  - å‘é‡æ•°é‡: {stats['vector_store']['num_vectors']}\n"
            f"  - ç»´åº¦: {stats['vector_store']['dimension']}\n\n"
            f"ğŸ•¸ï¸ å›¾å­˜å‚¨:\n"
            f"  - èŠ‚ç‚¹æ•°: {stats['graph_store']['num_nodes']}\n"
            f"  - è¾¹æ•°: {stats['graph_store']['num_edges']}\n\n"
            f"ğŸ“ å…ƒæ•°æ®å­˜å‚¨:\n"
            f"  - æ®µè½æ•°: {stats['metadata_store']['num_paragraphs']}\n"
            f"  - å…³ç³»æ•°: {stats['metadata_store']['num_relations']}\n"
            f"  - å®ä½“æ•°: {stats['metadata_store']['num_entities']}"
        )

        return {
            "success": True,
            "query_type": "stats",
            "content": content,
            "statistics": stats,
        }

    def get_tool_info_summary(self) -> str:
        """è·å–å·¥å…·ä¿¡æ¯æ‘˜è¦

        Returns:
            å·¥å…·ä¿¡æ¯æ‘˜è¦æ–‡æœ¬
        """
        if not self.retriever:
            return "âŒ çŸ¥è¯†æŸ¥è¯¢Toolæœªåˆå§‹åŒ–"

        lines = [
            "ğŸ”§ çŸ¥è¯†æŸ¥è¯¢Toolä¿¡æ¯",
            "",
            "ğŸ“‹ åŸºæœ¬ä¿¡æ¯:",
            f"  - åç§°: {self.name}",
            f"  - æè¿°: {self.description}",
            f"  - LLMå¯ç”¨: {'æ˜¯' if self.available_for_llm else 'å¦'}",
            "",
            "âš™ï¸ æ£€ç´¢é…ç½®:",
            f"  - Top-Kæ®µè½: {self.retriever.config.top_k_paragraphs}",
            f"  - Top-Kå…³ç³»: {self.retriever.config.top_k_relations}",
            f"  - èåˆç³»æ•°(alpha): {self.retriever.config.alpha}",
            f"  - PPRå¯ç”¨: {'æ˜¯' if self.retriever.config.enable_ppr else 'å¦'}",
            f"  - å¹¶è¡Œæ£€ç´¢: {'æ˜¯' if self.retriever.config.enable_parallel else 'å¦'}",
            "",
            "ğŸ“Š å­˜å‚¨ç»Ÿè®¡:",
            f"  - å‘é‡æ•°é‡: {self.vector_store.num_vectors if self.vector_store else 0}",
            f"  - èŠ‚ç‚¹æ•°é‡: {self.graph_store.num_nodes if self.graph_store else 0}",
            f"  - è¾¹æ•°é‡: {self.graph_store.num_edges if self.graph_store else 0}",
            f"  - æ®µè½æ•°é‡: {self.metadata_store.count_paragraphs() if self.metadata_store else 0}",
        ]

        return "\n".join(lines)
