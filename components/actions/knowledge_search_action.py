"""
çŸ¥è¯†æ£€ç´¢Actionç»„ä»¶

æä¾›åŸºäºŽåŒè·¯æ£€ç´¢çš„çŸ¥è¯†æœç´¢åŠŸèƒ½ã€‚
"""

import time
from typing import Tuple, Optional, List, Dict, Any
from pathlib import Path

from src.common.logger import get_logger
from src.plugin_system.base.base_action import BaseAction
from src.plugin_system.base.component_types import ActionActivationType
from src.chat.message_receive.chat_stream import ChatStream

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ...core import DualPathRetriever, RetrievalStrategy, DualPathRetrieverConfig

logger = get_logger("A_Memorix.KnowledgeSearchAction")


class KnowledgeSearchAction(BaseAction):
    """çŸ¥è¯†æ£€ç´¢Action

    åŠŸèƒ½ï¼š
    - åŒè·¯æ£€ç´¢ï¼ˆæ®µè½+å…³ç³»ï¼‰
    - æ™ºèƒ½ç»“æžœèžåˆ
    - PPRé‡æŽ’åº
    - åŠ¨æ€é˜ˆå€¼è¿‡æ»¤
    """

    # ActionåŸºæœ¬ä¿¡æ¯
    action_name = "knowledge_search"
    action_description = "åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³å†…å®¹ï¼Œæ”¯æŒæ®µè½å’Œå…³ç³»çš„åŒè·¯æ£€ç´¢"

    # æ¿€æ´»é…ç½®
    activation_type = ActionActivationType.ALWAYS
    parallel_action = True

    # Actionå‚æ•°
    action_parameters = {
        "query": {
            "type": "string",
            "description": "æœç´¢æŸ¥è¯¢æ–‡æœ¬",
            "required": True,
        },
        "top_k": {
            "type": "integer",
            "description": "è¿”å›žç»“æžœæ•°é‡",
            "default": 10,
            "min": 1,
            "max": 50,
        },
        "use_threshold": {
            "type": "boolean",
            "description": "æ˜¯å¦ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è¿‡æ»¤",
            "default": True,
        },
        "enable_ppr": {
            "type": "boolean",
            "description": "æ˜¯å¦å¯ç”¨PPRé‡æŽ’åº",
            "default": True,
        },
    }

    # Actionä¾èµ–
    action_require = ["vector_store", "graph_store", "metadata_store", "embedding_manager"]

    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢Action"""
        super().__init__(*args, **kwargs)

        # åˆå§‹åŒ–æ£€ç´¢å™¨
        self.retriever: Optional[DualPathRetriever] = None
        self._initialize_retriever()
 
    @property
    def debug_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è°ƒè¯•æ¨¡å¼"""
        advanced = self.plugin_config.get("advanced", {})
        if isinstance(advanced, dict):
            return advanced.get("debug", False)
        return self.plugin_config.get("debug", False)
 
    def _initialize_retriever(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        try:
            # ä»Žæ’ä»¶é…ç½®èŽ·å–å­˜å‚¨å®žä¾‹ (ä¼˜å…ˆä»Žé…ç½®èŽ·å–ï¼Œå…œåº•ä»Žæ’ä»¶å®žä¾‹èŽ·å–)
            vector_store = self.plugin_config.get("vector_store")
            graph_store = self.plugin_config.get("graph_store")
            metadata_store = self.plugin_config.get("metadata_store")
            embedding_manager = self.plugin_config.get("embedding_manager")

            # å…œåº•é€»è¾‘ï¼šå¦‚æžœé…ç½®ä¸­æ²¡æœ‰å­˜å‚¨å®žä¾‹ï¼Œå°è¯•ç›´æŽ¥ä»Žæ’ä»¶ç³»ç»ŸèŽ·å–
            # ä½¿ç”¨ is not None æ£€æŸ¥ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½å¸ƒå°”å€¼ä¸º False
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                from ...plugin import A_MemorixPlugin
                instances = A_MemorixPlugin.get_storage_instances()
                if instances:
                    vector_store = vector_store or instances.get("vector_store")
                    graph_store = graph_store or instances.get("graph_store")
                    metadata_store = metadata_store or instances.get("metadata_store")
                    embedding_manager = embedding_manager or instances.get("embedding_manager")


            # æœ€ç»ˆæ£€æŸ¥ (ä½¿ç”¨ is not None è€Œéžå¸ƒå°”å€¼ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½ä¸º False)
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                logger.warning(f"{self.log_prefix} å­˜å‚¨ç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨æ£€ç´¢åŠŸèƒ½")
                return

            # åˆ›å»ºæ£€ç´¢å™¨é…ç½®
            config = DualPathRetrieverConfig(
                top_k_paragraphs=self.get_config("retrieval.top_k_paragraphs", 20),
                top_k_relations=self.get_config("retrieval.top_k_relations", 10),
                top_k_final=self.get_config("retrieval.top_k_final", 10),
                alpha=self.get_config("retrieval.alpha", 0.5),
                enable_ppr=self.get_config("retrieval.enable_ppr", True),
                ppr_alpha=self.get_config("retrieval.ppr_alpha", 0.85),
                ppr_concurrency_limit=self.get_config("retrieval.ppr_concurrency_limit", 4),
                enable_parallel=self.get_config("retrieval.enable_parallel", True),
                retrieval_strategy=RetrievalStrategy.DUAL_PATH,
                debug=self.debug_enabled,
            )

            # åˆ›å»ºæ£€ç´¢å™¨
            self.retriever = DualPathRetriever(
                vector_store=vector_store,
                graph_store=graph_store,
                metadata_store=metadata_store,
                embedding_manager=embedding_manager,
                config=config,
            )

            logger.info(f"{self.log_prefix} çŸ¥è¯†æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"{self.log_prefix} æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.retriever = None

    async def execute(self) -> Tuple[bool, str]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢

        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, ç»“æžœæ–‡æœ¬)
        """
        # æ£€æŸ¥æ£€ç´¢å™¨æ˜¯å¦å¯ç”¨
        if not self.retriever:
            return False, "çŸ¥è¯†æ£€ç´¢å™¨æœªåˆå§‹åŒ–"

        # èŽ·å–æŸ¥è¯¢å‚æ•°
        query = self.action_data.get("query", "")
        if not query:
            return False, "æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º"

        top_k = self.action_data.get("top_k", 10)
        use_threshold = self.action_data.get("use_threshold", True)
        enable_ppr = self.action_data.get("enable_ppr", True)
        
        # 0. æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„èŠå¤©æµä¸­
        from ...plugin import A_MemorixPlugin
        plugin_instance = A_MemorixPlugin.get_global_instance()
        if plugin_instance:
             # èŽ·å–å½“å‰èŠå¤©æµID, ç¾¤ç»„ID, ç”¨æˆ·ID
            stream_id = self.chat_id
            group_id = self.group_id
            user_id = self.user_id
            
            if not plugin_instance.is_chat_enabled(stream_id, group_id, user_id):
                # å¦‚æžœæœªå¯ç”¨ï¼Œå®‰é™åœ°è¿”å›žï¼ˆè§†ä¸ºæˆåŠŸä½†æ— ç»“æžœï¼Œé¿å…æ‰“æ‰°ï¼‰
                logger.info(f"{self.log_prefix} èŠå¤©æµå·²è¢«è¿‡æ»¤é…ç½®ç¦ç”¨ï¼Œè·³è¿‡æ£€ç´¢")
                return True, ""

        logger.info(f"{self.log_prefix} å¼€å§‹çŸ¥è¯†æ£€ç´¢: query='{query}', top_k={top_k}")

        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()

            # æ‰§è¡Œæ£€ç´¢
            results = await self._search_knowledge(
                query=query,
                top_k=top_k,
                use_threshold=use_threshold,
                enable_ppr=enable_ppr,
            )

            # è®¡ç®—è€—æ—¶
            elapsed_ms = (time.time() - start_time) * 1000

            # æ ¼å¼åŒ–ç»“æžœ
            if not results:
                response = f"æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼ˆæ£€ç´¢è€—æ—¶: {elapsed_ms:.1f}msï¼‰"
                logger.info(f"{self.log_prefix} {response}")
                return True, response

            # æž„å»ºå“åº”
            response = self._format_results(results, query, elapsed_ms)

            logger.info(
                f"{self.log_prefix} æ£€ç´¢å®Œæˆ: è¿”å›ž{len(results)}æ¡ç»“æžœ, è€—æ—¶{elapsed_ms:.1f}ms"
            )

            return True, response

        except Exception as e:
            error_msg = f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}"
            logger.error(f"{self.log_prefix} {error_msg}")
            return False, error_msg

    async def _search_knowledge(
        self,
        query: str,
        top_k: int,
        use_threshold: bool,
        enable_ppr: bool,
    ) -> List[Any]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›žç»“æžœæ•°é‡
            use_threshold: æ˜¯å¦ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤
            enable_ppr: æ˜¯å¦å¯ç”¨PPR

        Returns:
            æ£€ç´¢ç»“æžœåˆ—è¡¨
        """
        # ä¸´æ—¶é…ç½®PPR
        original_ppr_setting = self.retriever.config.enable_ppr
        self.retriever.config.enable_ppr = enable_ppr

        try:
            # æ‰§è¡Œæ£€ç´¢ (å¼‚æ­¥)
            results = await self.retriever.retrieve(query, top_k=top_k)

            # åº”ç”¨é˜ˆå€¼è¿‡æ»¤
            if use_threshold and hasattr(self.retriever, "threshold_filter"):
                threshold_filter = self.retriever.threshold_filter
                if threshold_filter:
                    results = threshold_filter.filter(results)

            return results

        finally:
            # æ¢å¤åŽŸå§‹é…ç½®
            self.retriever.config.enable_ppr = original_ppr_setting

    def _format_results(self, results: List[Any], query: str, elapsed_ms: float) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢ç»“æžœ

        Args:
            results: æ£€ç´¢ç»“æžœåˆ—è¡¨
            query: åŽŸå§‹æŸ¥è¯¢
            elapsed_ms: æ£€ç´¢è€—æ—¶

        Returns:
            æ ¼å¼åŒ–çš„ç»“æžœæ–‡æœ¬
        """
        lines = []
        lines.append(f"ðŸ” çŸ¥è¯†æ£€ç´¢ç»“æžœï¼ˆæŸ¥è¯¢: '{query}'ï¼Œè€—æ—¶: {elapsed_ms:.1f}msï¼‰")
        lines.append("")

        # æŒ‰ç±»åž‹åˆ†ç»„
        paragraphs = []
        relations = []

        for result in results:
            if result.result_type == "paragraph":
                paragraphs.append(result)
            elif result.result_type == "relation":
                relations.append(result)

        # æ·»åŠ æ®µè½ç»“æžœ
        if paragraphs:
            lines.append("ðŸ“„ åŒ¹é…çš„æ®µè½ï¼š")
            for i, result in enumerate(paragraphs, 1):
                score_pct = result.score * 100
                lines.append(f"  {i}. [{score_pct:.1f}%] {result.content[:100]}...")
            lines.append("")

        # æ·»åŠ å…³ç³»ç»“æžœ
        if relations:
            lines.append("ðŸ”— åŒ¹é…çš„å…³ç³»ï¼š")
            for i, result in enumerate(relations, 1):
                score_pct = result.score * 100
                subject = result.metadata.get("subject", "")
                predicate = result.metadata.get("predicate", "")
                obj = result.metadata.get("object", "")
                lines.append(f"  {i}. [{score_pct:.1f}%] {subject} {predicate} {obj}")
            lines.append("")

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        lines.append(f"ðŸ“Š ç»Ÿè®¡: å…±{len(results)}æ¡ç»“æžœï¼ˆæ®µè½: {len(paragraphs)}, å…³ç³»: {len(relations)}ï¼‰")

        return "\n".join(lines)

    async def search_batch(
        self,
        queries: List[str],
        top_k: int = 10,
    ) -> Dict[str, List[Any]]:
        """æ‰¹é‡æ£€ç´¢çŸ¥è¯†

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›žçš„ç»“æžœæ•°

        Returns:
            æŸ¥è¯¢åˆ°ç»“æžœçš„æ˜ å°„ {query: results}
        """
        if not self.retriever:
            logger.error(f"{self.log_prefix} æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
            return {}

        results_map = {}

        for query in queries:
            try:
                results = self.retriever.retrieve(query, top_k=top_k)
                results_map[query] = results
                logger.info(
                    f"{self.log_prefix} æ‰¹é‡æ£€ç´¢: '{query}' -> {len(results)}æ¡ç»“æžœ"
                )
            except Exception as e:
                logger.error(f"{self.log_prefix} æ‰¹é‡æ£€ç´¢å¤±è´¥ '{query}': {e}")
                results_map[query] = []

        return results_map

    def get_statistics(self) -> Dict[str, Any]:
        """èŽ·å–æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.retriever:
            return {
                "status": "not_initialized",
            }

        stats = {
            "status": "active",
            "config": {
                "top_k_paragraphs": self.retriever.config.top_k_paragraphs,
                "top_k_relations": self.retriever.config.top_k_relations,
                "alpha": self.retriever.config.alpha,
                "enable_ppr": self.retriever.config.enable_ppr,
                "enable_parallel": self.retriever.config.enable_parallel,
                "retrieval_strategy": self.retriever.config.retrieval_strategy.value,
            },
        }

        # æ·»åŠ å­˜å‚¨ç»Ÿè®¡
        if hasattr(self.retriever, "vector_store"):
            stats["vector_store"] = {
                "num_vectors": self.retriever.vector_store.num_vectors,
                "dimension": self.retriever.vector_store.dimension,
            }

        if hasattr(self.retriever, "graph_store"):
            stats["graph_store"] = {
                "num_nodes": self.retriever.graph_store.num_nodes,
                "num_edges": self.retriever.graph_store.num_edges,
            }

        return stats

    def __repr__(self) -> str:
        return (
            f"KnowledgeSearchAction("
            f"retriever_initialized={self.retriever is not None})"
        )
