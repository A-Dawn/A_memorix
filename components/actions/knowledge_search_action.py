"""
çŸ¥è¯†æ£€ç´¢Actionç»„ä»¶

æä¾›åŸºäºŽåŒè·¯æ£€ç´¢çš„çŸ¥è¯†æœç´¢åŠŸèƒ½ã€‚
"""

import time
from typing import Tuple, Optional, List, Dict, Any
from pathlib import Path

from src.common.logger import get_logger
from src.plugin_system.base.base_action import BaseAction
from src.plugin_system.base.component_types import ActionActivationType
from src.chat.message_receive.chat_stream import ChatStream

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ...core import (
    DualPathRetriever,
    RetrievalStrategy,
    DualPathRetrieverConfig,
    TemporalQueryOptions,
    SparseBM25Config,
    FusionConfig,
)
from ...core.utils.time_parser import parse_query_time_range

logger = get_logger("A_Memorix.KnowledgeSearchAction")


class KnowledgeSearchAction(BaseAction):
    """çŸ¥è¯†æ£€ç´¢Action

    åŠŸèƒ½ï¼š
    - åŒè·¯æ£€ç´¢ï¼ˆæ®µè½+å…³ç³»ï¼‰
    - æ™ºèƒ½ç»“æžœèžåˆ
    - PPRé‡æŽ’åº
    - åŠ¨æ€é˜ˆå€¼è¿‡æ»¤
    """

    # ActionåŸºæœ¬ä¿¡æ¯
    action_name = "knowledge_search"
    action_description = "åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³å†…å®¹ï¼Œæ”¯æŒæ®µè½å’Œå…³ç³»çš„åŒè·¯æ£€ç´¢"

    # æ¿€æ´»é…ç½®
    activation_type = ActionActivationType.ALWAYS
    parallel_action = True

    # Actionå‚æ•°
    action_parameters = {
        "query_type": {
            "type": "string",
            "description": "æŸ¥è¯¢æ¨¡å¼: semantic(è¯­ä¹‰)ã€time(æ—¶é—´)ã€hybrid(è¯­ä¹‰+æ—¶é—´)",
            "required": False,
            "enum": ["semantic", "time", "hybrid"],
            "default": "semantic",
        },
        "query": {
            "type": "string",
            "description": "æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼ˆsemantic/hybridå¿…å¡«ï¼Œtimeå¯é€‰ï¼‰",
            "required": False,
        },
        "time_from": {
            "type": "string",
            "description": "å¼€å§‹æ—¶é—´ï¼Œä»…æ”¯æŒ YYYY/MM/DD æˆ– YYYY/MM/DD HH:mmï¼ˆæ—¥æœŸè‡ªåŠ¨æŒ‰ 00:00 å±•å¼€ï¼‰",
            "required": False,
        },
        "time_to": {
            "type": "string",
            "description": "ç»“æŸæ—¶é—´ï¼Œä»…æ”¯æŒ YYYY/MM/DD æˆ– YYYY/MM/DD HH:mmï¼ˆæ—¥æœŸè‡ªåŠ¨æŒ‰ 23:59 å±•å¼€ï¼‰",
            "required": False,
        },
        "person": {
            "type": "string",
            "description": "æŒ‰äººç‰©è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰",
            "required": False,
        },
        "source": {
            "type": "string",
            "description": "æŒ‰æ¥æºè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰",
            "required": False,
        },
        "top_k": {
            "type": "integer",
            "description": "è¿”å›žç»“æžœæ•°é‡",
            "default": 10,
            "min": 1,
            "max": 50,
        },
        "use_threshold": {
            "type": "boolean",
            "description": "æ˜¯å¦ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è¿‡æ»¤",
            "default": True,
        },
        "enable_ppr": {
            "type": "boolean",
            "description": "æ˜¯å¦å¯ç”¨PPRé‡æŽ’åº",
            "default": True,
        },
    }

    # Actionä¾èµ–
    action_require = ["vector_store", "graph_store", "metadata_store", "embedding_manager"]

    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢Action"""
        super().__init__(*args, **kwargs)

        # åˆå§‹åŒ–æ£€ç´¢å™¨
        self.retriever: Optional[DualPathRetriever] = None
        self._initialize_retriever()
 
    @property
    def debug_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è°ƒè¯•æ¨¡å¼"""
        advanced = self.plugin_config.get("advanced", {})
        if isinstance(advanced, dict):
            return advanced.get("debug", False)
        return self.plugin_config.get("debug", False)
 
    def _initialize_retriever(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        try:
            # ä»Žæ’ä»¶é…ç½®èŽ·å–å­˜å‚¨å®žä¾‹ (ä¼˜å…ˆä»Žé…ç½®èŽ·å–ï¼Œå…œåº•ä»Žæ’ä»¶å®žä¾‹èŽ·å–)
            vector_store = self.plugin_config.get("vector_store")
            graph_store = self.plugin_config.get("graph_store")
            metadata_store = self.plugin_config.get("metadata_store")
            embedding_manager = self.plugin_config.get("embedding_manager")
            sparse_index = self.plugin_config.get("sparse_index")

            # å…œåº•é€»è¾‘ï¼šå¦‚æžœé…ç½®ä¸­æ²¡æœ‰å­˜å‚¨å®žä¾‹ï¼Œå°è¯•ç›´æŽ¥ä»Žæ’ä»¶ç³»ç»ŸèŽ·å–
            # ä½¿ç”¨ is not None æ£€æŸ¥ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½å¸ƒå°”å€¼ä¸º False
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                from ...plugin import A_MemorixPlugin
                instances = A_MemorixPlugin.get_storage_instances()
                if instances:
                    vector_store = vector_store or instances.get("vector_store")
                    graph_store = graph_store or instances.get("graph_store")
                    metadata_store = metadata_store or instances.get("metadata_store")
                    embedding_manager = embedding_manager or instances.get("embedding_manager")
                    sparse_index = sparse_index or instances.get("sparse_index")


            # æœ€ç»ˆæ£€æŸ¥ (ä½¿ç”¨ is not None è€Œéžå¸ƒå°”å€¼ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½ä¸º False)
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                logger.warning(f"{self.log_prefix} å­˜å‚¨ç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨æ£€ç´¢åŠŸèƒ½")
                return

            # åˆ›å»ºæ£€ç´¢å™¨é…ç½®
            sparse_cfg_raw = self.get_config("retrieval.sparse", {}) or {}
            if not isinstance(sparse_cfg_raw, dict):
                sparse_cfg_raw = {}
            fusion_cfg_raw = self.get_config("retrieval.fusion", {}) or {}
            if not isinstance(fusion_cfg_raw, dict):
                fusion_cfg_raw = {}
            try:
                sparse_cfg = SparseBM25Config(**sparse_cfg_raw)
            except Exception as e:
                logger.warning(f"{self.log_prefix} sparse é…ç½®éžæ³•ï¼Œå›žé€€é»˜è®¤: {e}")
                sparse_cfg = SparseBM25Config()
            try:
                fusion_cfg = FusionConfig(**fusion_cfg_raw)
            except Exception as e:
                logger.warning(f"{self.log_prefix} fusion é…ç½®éžæ³•ï¼Œå›žé€€é»˜è®¤: {e}")
                fusion_cfg = FusionConfig()

            config = DualPathRetrieverConfig(
                top_k_paragraphs=self.get_config("retrieval.top_k_paragraphs", 20),
                top_k_relations=self.get_config("retrieval.top_k_relations", 10),
                top_k_final=self.get_config("retrieval.top_k_final", 10),
                alpha=self.get_config("retrieval.alpha", 0.5),
                enable_ppr=self.get_config("retrieval.enable_ppr", True),
                ppr_alpha=self.get_config("retrieval.ppr_alpha", 0.85),
                ppr_concurrency_limit=self.get_config("retrieval.ppr_concurrency_limit", 4),
                enable_parallel=self.get_config("retrieval.enable_parallel", True),
                retrieval_strategy=RetrievalStrategy.DUAL_PATH,
                debug=self.debug_enabled,
                sparse=sparse_cfg,
                fusion=fusion_cfg,
            )

            # åˆ›å»ºæ£€ç´¢å™¨
            self.retriever = DualPathRetriever(
                vector_store=vector_store,
                graph_store=graph_store,
                metadata_store=metadata_store,
                embedding_manager=embedding_manager,
                sparse_index=sparse_index,
                config=config,
            )

            logger.info(f"{self.log_prefix} çŸ¥è¯†æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"{self.log_prefix} æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.retriever = None

    async def execute(self) -> Tuple[bool, str]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢

        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, ç»“æžœæ–‡æœ¬)
        """
        # æ£€æŸ¥æ£€ç´¢å™¨æ˜¯å¦å¯ç”¨
        if not self.retriever:
            return False, "çŸ¥è¯†æ£€ç´¢å™¨æœªåˆå§‹åŒ–"

        # èŽ·å–æŸ¥è¯¢å‚æ•°
        query = str(self.action_data.get("query", "") or "").strip()
        query_type = str(self.action_data.get("query_type", "") or "").strip().lower()
        time_from_raw = self.action_data.get("time_from")
        time_to_raw = self.action_data.get("time_to")
        person = self.action_data.get("person")
        source = self.action_data.get("source")
        top_k_raw = self.action_data.get("top_k")
        use_threshold = self.action_data.get("use_threshold", True)
        enable_ppr = self.action_data.get("enable_ppr", True)
        if not query_type:
            if time_from_raw or time_to_raw:
                query_type = "hybrid" if query else "time"
            else:
                query_type = "semantic"

        if query_type not in {"semantic", "time", "hybrid"}:
            return False, f"query_type æ— æ•ˆ: {query_type}ï¼ˆä»…æ”¯æŒ semantic/time/hybridï¼‰"

        if query_type in {"semantic", "hybrid"} and not query:
            return False, "semantic/hybrid æ¨¡å¼å¿…é¡»æä¾› query"

        temporal_enabled = bool(self.get_config("retrieval.temporal.enabled", True))
        if query_type in {"time", "hybrid"} and not temporal_enabled:
            return False, "æ—¶åºæ£€ç´¢å·²ç¦ç”¨ï¼ˆretrieval.temporal.enabled=falseï¼‰"

        temporal_default_top_k = int(
            self.get_config("retrieval.temporal.default_top_k", 10)
        )
        default_top_k = temporal_default_top_k if query_type in {"time", "hybrid"} else 10
        if top_k_raw is None:
            top_k = default_top_k
        else:
            try:
                top_k = int(top_k_raw)
            except (TypeError, ValueError):
                return False, "top_k å‚æ•°å¿…é¡»ä¸ºæ•´æ•°"
        top_k = max(1, min(50, top_k))

        temporal: Optional[TemporalQueryOptions] = None
        if query_type in {"time", "hybrid"}:
            if not time_from_raw and not time_to_raw:
                return False, "time/hybrid æ¨¡å¼è‡³å°‘éœ€è¦ time_from æˆ– time_to"
            try:
                ts_from, ts_to = parse_query_time_range(
                    str(time_from_raw) if time_from_raw is not None else None,
                    str(time_to_raw) if time_to_raw is not None else None,
                )
            except ValueError as e:
                return False, f"æ—¶é—´å‚æ•°é”™è¯¯: {e}"
            temporal = TemporalQueryOptions(
                time_from=ts_from,
                time_to=ts_to,
                person=str(person).strip() if person else None,
                source=str(source).strip() if source else None,
                allow_created_fallback=self.get_config(
                    "retrieval.temporal.allow_created_fallback",
                    True,
                ),
                candidate_multiplier=int(
                    self.get_config("retrieval.temporal.candidate_multiplier", 8)
                ),
                max_scan=int(self.get_config("retrieval.temporal.max_scan", 1000)),
            )

        # 0. æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„èŠå¤©æµä¸­
        from ...plugin import A_MemorixPlugin
        plugin_instance = A_MemorixPlugin.get_global_instance()
        if plugin_instance:
             # èŽ·å–å½“å‰èŠå¤©æµID, ç¾¤ç»„ID, ç”¨æˆ·ID
            stream_id = self.chat_id
            group_id = self.group_id
            user_id = self.user_id
            
            if not plugin_instance.is_chat_enabled(stream_id, group_id, user_id):
                # å¦‚æžœæœªå¯ç”¨ï¼Œå®‰é™åœ°è¿”å›žï¼ˆè§†ä¸ºæˆåŠŸä½†æ— ç»“æžœï¼Œé¿å…æ‰“æ‰°ï¼‰
                logger.info(f"{self.log_prefix} èŠå¤©æµå·²è¢«è¿‡æ»¤é…ç½®ç¦ç”¨ï¼Œè·³è¿‡æ£€ç´¢")
                return True, ""

        logger.info(
            f"{self.log_prefix} å¼€å§‹çŸ¥è¯†æ£€ç´¢: query_type={query_type}, query='{query}', top_k={top_k}"
        )

        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()

            # æ‰§è¡Œæ£€ç´¢
            results = await self._search_knowledge(
                query=query,
                top_k=top_k,
                use_threshold=use_threshold,
                enable_ppr=enable_ppr,
                temporal=temporal,
            )

            # è®¡ç®—è€—æ—¶
            elapsed_ms = (time.time() - start_time) * 1000

            # æ ¼å¼åŒ–ç»“æžœ
            if not results:
                response = f"æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼ˆæ£€ç´¢è€—æ—¶: {elapsed_ms:.1f}msï¼‰"
                logger.info(f"{self.log_prefix} {response}")
                return True, response

            # æž„å»ºå“åº”
            query_display = query if query else "N/A"
            response = self._format_results(results, query_display, elapsed_ms)

            logger.info(
                f"{self.log_prefix} æ£€ç´¢å®Œæˆ: è¿”å›ž{len(results)}æ¡ç»“æžœ, è€—æ—¶{elapsed_ms:.1f}ms"
            )

            return True, response

        except Exception as e:
            error_msg = f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {str(e)}"
            logger.error(f"{self.log_prefix} {error_msg}")
            return False, error_msg

    async def _search_knowledge(
        self,
        query: str,
        top_k: int,
        use_threshold: bool,
        enable_ppr: bool,
        temporal: Optional[TemporalQueryOptions] = None,
    ) -> List[Any]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›žç»“æžœæ•°é‡
            use_threshold: æ˜¯å¦ä½¿ç”¨é˜ˆå€¼è¿‡æ»¤
            enable_ppr: æ˜¯å¦å¯ç”¨PPR

        Returns:
            æ£€ç´¢ç»“æžœåˆ—è¡¨
        """
        # ä¸´æ—¶é…ç½®PPR
        original_ppr_setting = self.retriever.config.enable_ppr
        self.retriever.config.enable_ppr = enable_ppr

        try:
            # æ‰§è¡Œæ£€ç´¢ (å¼‚æ­¥)
            results = await self.retriever.retrieve(
                query,
                top_k=top_k,
                temporal=temporal,
            )

            # åº”ç”¨é˜ˆå€¼è¿‡æ»¤
            if use_threshold and hasattr(self.retriever, "threshold_filter"):
                threshold_filter = self.retriever.threshold_filter
                if threshold_filter:
                    results = threshold_filter.filter(results)

            # V5: Hook for Memory Reinforcement
            from ...plugin import A_MemorixPlugin
            plugin_instance = A_MemorixPlugin.get_global_instance()
            if plugin_instance:
                 # Reinforce only relations that survived filtering
                 relation_hashes = [
                     r.hash_value for r in results if r.result_type == "relation"
                 ]
                 if relation_hashes:
                     # Fire and forget (it pushes to buffer)
                     await plugin_instance.reinforce_access(relation_hashes)

            return results

        finally:
            # æ¢å¤åŽŸå§‹é…ç½®
            self.retriever.config.enable_ppr = original_ppr_setting

    def _format_results(self, results: List[Any], query: str, elapsed_ms: float) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢ç»“æžœ

        Args:
            results: æ£€ç´¢ç»“æžœåˆ—è¡¨
            query: åŽŸå§‹æŸ¥è¯¢
            elapsed_ms: æ£€ç´¢è€—æ—¶

        Returns:
            æ ¼å¼åŒ–çš„ç»“æžœæ–‡æœ¬
        """
        lines = []
        lines.append(f"ðŸ” çŸ¥è¯†æ£€ç´¢ç»“æžœï¼ˆæŸ¥è¯¢: '{query}'ï¼Œè€—æ—¶: {elapsed_ms:.1f}msï¼‰")
        lines.append("")

        # æŒ‰ç±»åž‹åˆ†ç»„
        paragraphs = []
        relations = []

        for result in results:
            if result.result_type == "paragraph":
                paragraphs.append(result)
            elif result.result_type == "relation":
                relations.append(result)

        # æ·»åŠ æ®µè½ç»“æžœ
        if paragraphs:
            lines.append("ðŸ“„ åŒ¹é…çš„æ®µè½ï¼š")
            for i, result in enumerate(paragraphs, 1):
                score_pct = result.score * 100
                summary = result.content[:100] + ("..." if len(result.content) > 100 else "")
                lines.append(f"  {i}. [{score_pct:.1f}%] {summary}")
                time_meta = result.metadata.get("time_meta", {})
                if time_meta:
                    basis = time_meta.get("match_basis", "none")
                    s_text = time_meta.get("effective_start_text") or "N/A"
                    e_text = time_meta.get("effective_end_text") or "N/A"
                    lines.append(f"     â±ï¸ {s_text} ~ {e_text} ({basis})")
            lines.append("")

        # æ·»åŠ å…³ç³»ç»“æžœ
        if relations:
            lines.append("ðŸ”— åŒ¹é…çš„å…³ç³»ï¼š")
            for i, result in enumerate(relations, 1):
                score_pct = result.score * 100
                subject = result.metadata.get("subject", "")
                predicate = result.metadata.get("predicate", "")
                obj = result.metadata.get("object", "")
                lines.append(f"  {i}. [{score_pct:.1f}%] {subject} {predicate} {obj}")
                time_meta = result.metadata.get("time_meta", {})
                if time_meta:
                    basis = time_meta.get("match_basis", "none")
                    s_text = time_meta.get("effective_start_text") or "N/A"
                    e_text = time_meta.get("effective_end_text") or "N/A"
                    lines.append(f"     â±ï¸ {s_text} ~ {e_text} ({basis})")
            lines.append("")

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        lines.append(f"ðŸ“Š ç»Ÿè®¡: å…±{len(results)}æ¡ç»“æžœï¼ˆæ®µè½: {len(paragraphs)}, å…³ç³»: {len(relations)}ï¼‰")

        return "\n".join(lines)

    async def search_batch(
        self,
        queries: List[str],
        top_k: int = 10,
    ) -> Dict[str, List[Any]]:
        """æ‰¹é‡æ£€ç´¢çŸ¥è¯†

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›žçš„ç»“æžœæ•°

        Returns:
            æŸ¥è¯¢åˆ°ç»“æžœçš„æ˜ å°„ {query: results}
        """
        if not self.retriever:
            logger.error(f"{self.log_prefix} æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
            return {}

        results_map = {}

        for query in queries:
            try:
                results = self.retriever.retrieve(query, top_k=top_k)
                results_map[query] = results
                logger.info(
                    f"{self.log_prefix} æ‰¹é‡æ£€ç´¢: '{query}' -> {len(results)}æ¡ç»“æžœ"
                )
            except Exception as e:
                logger.error(f"{self.log_prefix} æ‰¹é‡æ£€ç´¢å¤±è´¥ '{query}': {e}")
                results_map[query] = []

        return results_map

    def get_statistics(self) -> Dict[str, Any]:
        """èŽ·å–æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.retriever:
            return {
                "status": "not_initialized",
            }

        stats = {
            "status": "active",
            "config": {
                "top_k_paragraphs": self.retriever.config.top_k_paragraphs,
                "top_k_relations": self.retriever.config.top_k_relations,
                "alpha": self.retriever.config.alpha,
                "enable_ppr": self.retriever.config.enable_ppr,
                "enable_parallel": self.retriever.config.enable_parallel,
                "retrieval_strategy": self.retriever.config.retrieval_strategy.value,
            },
        }

        # æ·»åŠ å­˜å‚¨ç»Ÿè®¡
        if hasattr(self.retriever, "vector_store"):
            stats["vector_store"] = {
                "num_vectors": self.retriever.vector_store.num_vectors,
                "dimension": self.retriever.vector_store.dimension,
            }

        if hasattr(self.retriever, "graph_store"):
            stats["graph_store"] = {
                "num_nodes": self.retriever.graph_store.num_nodes,
                "num_edges": self.retriever.graph_store.num_edges,
            }

        return stats

    def __repr__(self) -> str:
        return (
            f"KnowledgeSearchAction("
            f"retriever_initialized={self.retriever is not None})"
        )
