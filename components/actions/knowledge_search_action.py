"""
çŸ¥è¯†æ£€ç´¢Actionç»„ä»¶

æä¾›åŸºäºŽåŒè·¯æ£€ç´¢çš„çŸ¥è¯†æœç´¢åŠŸèƒ½ã€‚
"""

from typing import Tuple, Optional, List, Dict, Any

from src.common.logger import get_logger
from src.plugin_system.base.base_action import BaseAction
from src.plugin_system.base.component_types import ActionActivationType
from src.chat.message_receive.chat_stream import ChatStream

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from ...core import (
    DualPathRetriever,
    RetrievalStrategy,
    DualPathRetrieverConfig,
    DynamicThresholdFilter,
    ThresholdConfig,
    ThresholdMethod,
    SparseBM25Config,
    FusionConfig,
)
from ...core.utils.search_execution_service import (
    SearchExecutionRequest,
    SearchExecutionService,
)

logger = get_logger("A_Memorix.KnowledgeSearchAction")


class KnowledgeSearchAction(BaseAction):
    """çŸ¥è¯†æ£€ç´¢Action

    åŠŸèƒ½ï¼š
    - åŒè·¯æ£€ç´¢ï¼ˆæ®µè½+å…³ç³»ï¼‰
    - æ™ºèƒ½ç»“æžœèžåˆ
    - PPRé‡æŽ’åº
    - åŠ¨æ€é˜ˆå€¼è¿‡æ»¤
    """

    # ActionåŸºæœ¬ä¿¡æ¯
    action_name = "knowledge_search"
    action_description = "åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³å†…å®¹ï¼Œæ”¯æŒæ®µè½å’Œå…³ç³»çš„åŒè·¯æ£€ç´¢"

    # æ¿€æ´»é…ç½®
    activation_type = ActionActivationType.ALWAYS
    parallel_action = True

    # Actionå‚æ•°
    action_parameters = {
        "query_type": {
            "type": "string",
            "description": "æŸ¥è¯¢æ¨¡å¼: semantic(è¯­ä¹‰)ã€time(æ—¶é—´)ã€hybrid(è¯­ä¹‰+æ—¶é—´)",
            "required": False,
            "enum": ["semantic", "time", "hybrid"],
            "default": "semantic",
        },
        "query": {
            "type": "string",
            "description": "æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼ˆsemantic/hybridå¿…å¡«ï¼Œtimeå¯é€‰ï¼‰",
            "required": False,
        },
        "time_from": {
            "type": "string",
            "description": "å¼€å§‹æ—¶é—´ï¼Œä»…æ”¯æŒ YYYY/MM/DD æˆ– YYYY/MM/DD HH:mmï¼ˆæ—¥æœŸè‡ªåŠ¨æŒ‰ 00:00 å±•å¼€ï¼‰",
            "required": False,
        },
        "time_to": {
            "type": "string",
            "description": "ç»“æŸæ—¶é—´ï¼Œä»…æ”¯æŒ YYYY/MM/DD æˆ– YYYY/MM/DD HH:mmï¼ˆæ—¥æœŸè‡ªåŠ¨æŒ‰ 23:59 å±•å¼€ï¼‰",
            "required": False,
        },
        "person": {
            "type": "string",
            "description": "æŒ‰äººç‰©è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰",
            "required": False,
        },
        "source": {
            "type": "string",
            "description": "æŒ‰æ¥æºè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰",
            "required": False,
        },
        "top_k": {
            "type": "integer",
            "description": "è¿”å›žç»“æžœæ•°é‡",
            "default": 10,
            "min": 1,
            "max": 50,
        },
        "use_threshold": {
            "type": "boolean",
            "description": "æ˜¯å¦ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è¿‡æ»¤",
            "default": True,
        },
        "enable_ppr": {
            "type": "boolean",
            "description": "æ˜¯å¦å¯ç”¨PPRé‡æŽ’åº",
            "default": True,
        },
    }

    # Actionä¾èµ–
    action_require = ["vector_store", "graph_store", "metadata_store", "embedding_manager"]

    def __init__(self, *args, **kwargs):
        """åˆå§‹åŒ–çŸ¥è¯†æ£€ç´¢Action"""
        super().__init__(*args, **kwargs)

        # åˆå§‹åŒ–æ£€ç´¢å™¨
        self.retriever: Optional[DualPathRetriever] = None
        self.threshold_filter: Optional[DynamicThresholdFilter] = None
        self._initialize_retriever()
 
    @property
    def debug_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è°ƒè¯•æ¨¡å¼"""
        advanced = self.plugin_config.get("advanced", {})
        if isinstance(advanced, dict):
            return advanced.get("debug", False)
        return self.plugin_config.get("debug", False)
 
    def _initialize_retriever(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        try:
            # ä»Žæ’ä»¶é…ç½®èŽ·å–å­˜å‚¨å®žä¾‹ (ä¼˜å…ˆä»Žé…ç½®èŽ·å–ï¼Œå…œåº•ä»Žæ’ä»¶å®žä¾‹èŽ·å–)
            vector_store = self.plugin_config.get("vector_store")
            graph_store = self.plugin_config.get("graph_store")
            metadata_store = self.plugin_config.get("metadata_store")
            embedding_manager = self.plugin_config.get("embedding_manager")
            sparse_index = self.plugin_config.get("sparse_index")

            # å…œåº•é€»è¾‘ï¼šå¦‚æžœé…ç½®ä¸­æ²¡æœ‰å­˜å‚¨å®žä¾‹ï¼Œå°è¯•ç›´æŽ¥ä»Žæ’ä»¶ç³»ç»ŸèŽ·å–
            # ä½¿ç”¨ is not None æ£€æŸ¥ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½å¸ƒå°”å€¼ä¸º False
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                from ...plugin import A_MemorixPlugin
                instances = A_MemorixPlugin.get_storage_instances()
                if instances:
                    vector_store = vector_store or instances.get("vector_store")
                    graph_store = graph_store or instances.get("graph_store")
                    metadata_store = metadata_store or instances.get("metadata_store")
                    embedding_manager = embedding_manager or instances.get("embedding_manager")
                    sparse_index = sparse_index or instances.get("sparse_index")


            # æœ€ç»ˆæ£€æŸ¥ (ä½¿ç”¨ is not None è€Œéžå¸ƒå°”å€¼ï¼Œå› ä¸ºç©ºå¯¹è±¡å¯èƒ½ä¸º False)
            if not all([
                vector_store is not None,
                graph_store is not None,
                metadata_store is not None,
                embedding_manager is not None
            ]):
                logger.warning(f"{self.log_prefix} å­˜å‚¨ç»„ä»¶æœªå®Œå…¨åˆå§‹åŒ–ï¼Œæ— æ³•ä½¿ç”¨æ£€ç´¢åŠŸèƒ½")
                return

            # åˆ›å»ºæ£€ç´¢å™¨é…ç½®
            sparse_cfg_raw = self.get_config("retrieval.sparse", {}) or {}
            if not isinstance(sparse_cfg_raw, dict):
                sparse_cfg_raw = {}
            fusion_cfg_raw = self.get_config("retrieval.fusion", {}) or {}
            if not isinstance(fusion_cfg_raw, dict):
                fusion_cfg_raw = {}
            try:
                sparse_cfg = SparseBM25Config(**sparse_cfg_raw)
            except Exception as e:
                logger.warning(f"{self.log_prefix} sparse é…ç½®éžæ³•ï¼Œå›žé€€é»˜è®¤: {e}")
                sparse_cfg = SparseBM25Config()
            try:
                fusion_cfg = FusionConfig(**fusion_cfg_raw)
            except Exception as e:
                logger.warning(f"{self.log_prefix} fusion é…ç½®éžæ³•ï¼Œå›žé€€é»˜è®¤: {e}")
                fusion_cfg = FusionConfig()

            config = DualPathRetrieverConfig(
                top_k_paragraphs=self.get_config("retrieval.top_k_paragraphs", 20),
                top_k_relations=self.get_config("retrieval.top_k_relations", 10),
                top_k_final=self.get_config("retrieval.top_k_final", 10),
                alpha=self.get_config("retrieval.alpha", 0.5),
                enable_ppr=self.get_config("retrieval.enable_ppr", True),
                ppr_alpha=self.get_config("retrieval.ppr_alpha", 0.85),
                ppr_concurrency_limit=self.get_config("retrieval.ppr_concurrency_limit", 4),
                enable_parallel=self.get_config("retrieval.enable_parallel", True),
                retrieval_strategy=RetrievalStrategy.DUAL_PATH,
                debug=self.debug_enabled,
                sparse=sparse_cfg,
                fusion=fusion_cfg,
            )

            # åˆ›å»ºæ£€ç´¢å™¨
            self.retriever = DualPathRetriever(
                vector_store=vector_store,
                graph_store=graph_store,
                metadata_store=metadata_store,
                embedding_manager=embedding_manager,
                sparse_index=sparse_index,
                config=config,
            )

            threshold_config = ThresholdConfig(
                method=ThresholdMethod.ADAPTIVE,
                min_threshold=self.get_config("threshold.min_threshold", 0.3),
                max_threshold=self.get_config("threshold.max_threshold", 0.95),
                percentile=self.get_config("threshold.percentile", 75.0),
                std_multiplier=self.get_config("threshold.std_multiplier", 1.5),
                min_results=self.get_config("threshold.min_results", 3),
                enable_auto_adjust=self.get_config("threshold.enable_auto_adjust", True),
            )
            self.threshold_filter = DynamicThresholdFilter(threshold_config)

            logger.info(f"{self.log_prefix} çŸ¥è¯†æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"{self.log_prefix} æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.retriever = None

    async def execute(self) -> Tuple[bool, str]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢

        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, ç»“æžœæ–‡æœ¬)
        """
        # æ£€æŸ¥æ£€ç´¢å™¨æ˜¯å¦å¯ç”¨
        if not self.retriever:
            return False, "çŸ¥è¯†æ£€ç´¢å™¨æœªåˆå§‹åŒ–"

        # èŽ·å–æŸ¥è¯¢å‚æ•°
        query = str(self.action_data.get("query", "") or "").strip()
        query_type = str(self.action_data.get("query_type", "") or "").strip().lower()
        time_from_raw = self.action_data.get("time_from")
        time_to_raw = self.action_data.get("time_to")
        person = self.action_data.get("person")
        source = self.action_data.get("source")
        top_k_raw = self.action_data.get("top_k")
        use_threshold = self.action_data.get("use_threshold", True)
        enable_ppr = self.action_data.get("enable_ppr", True)
        if not query_type:
            if time_from_raw or time_to_raw:
                query_type = "hybrid" if query else "time"
            else:
                query_type = "semantic"
        search_owner = str(self.get_config("routing.search_owner", "action") or "action").strip().lower()
        if search_owner == "tool":
            logger.info(f"{self.log_prefix} routing.search_owner=toolï¼ŒActionæ£€ç´¢é“¾è·¯è·³è¿‡")
            return True, ""

        request = SearchExecutionRequest(
            caller="action",
            stream_id=self.chat_id,
            group_id=self.group_id,
            user_id=self.user_id,
            query_type=query_type,
            query=query,
            top_k=top_k_raw,
            time_from=str(time_from_raw) if time_from_raw is not None else None,
            time_to=str(time_to_raw) if time_to_raw is not None else None,
            person=str(person).strip() if person else None,
            source=str(source).strip() if source else None,
            use_threshold=bool(use_threshold),
            enable_ppr=bool(enable_ppr),
        )

        execution = await SearchExecutionService.execute(
            retriever=self.retriever,
            threshold_filter=self.threshold_filter,
            plugin_config=self.plugin_config,
            request=request,
            enforce_chat_filter=True,
            reinforce_access=True,
        )
        if not execution.success:
            return False, execution.error

        if execution.chat_filtered:
            return True, ""

        results = execution.results
        elapsed_ms = execution.elapsed_ms
        if not results:
            response = f"æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ï¼ˆæ£€ç´¢è€—æ—¶: {elapsed_ms:.1f}msï¼‰"
            logger.info(f"{self.log_prefix} {response}")
            return True, response

        query_display = query if query else "N/A"
        response = self._format_results(results, query_display, elapsed_ms)
        logger.info(
            f"{self.log_prefix} æ£€ç´¢å®Œæˆ: è¿”å›ž{len(results)}æ¡ç»“æžœ, è€—æ—¶{elapsed_ms:.1f}ms"
        )
        return True, response

    def _format_results(self, results: List[Any], query: str, elapsed_ms: float) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢ç»“æžœ

        Args:
            results: æ£€ç´¢ç»“æžœåˆ—è¡¨
            query: åŽŸå§‹æŸ¥è¯¢
            elapsed_ms: æ£€ç´¢è€—æ—¶

        Returns:
            æ ¼å¼åŒ–çš„ç»“æžœæ–‡æœ¬
        """
        lines = []
        lines.append(f"ðŸ” çŸ¥è¯†æ£€ç´¢ç»“æžœï¼ˆæŸ¥è¯¢: '{query}'ï¼Œè€—æ—¶: {elapsed_ms:.1f}msï¼‰")
        lines.append("")

        # æŒ‰ç±»åž‹åˆ†ç»„
        paragraphs = []
        relations = []

        for result in results:
            if result.result_type == "paragraph":
                paragraphs.append(result)
            elif result.result_type == "relation":
                relations.append(result)

        # æ·»åŠ æ®µè½ç»“æžœ
        if paragraphs:
            lines.append("ðŸ“„ åŒ¹é…çš„æ®µè½ï¼š")
            for i, result in enumerate(paragraphs, 1):
                score_pct = result.score * 100
                summary = result.content[:100] + ("..." if len(result.content) > 100 else "")
                lines.append(f"  {i}. [{score_pct:.1f}%] {summary}")
                time_meta = result.metadata.get("time_meta", {})
                if time_meta:
                    basis = time_meta.get("match_basis", "none")
                    s_text = time_meta.get("effective_start_text") or "N/A"
                    e_text = time_meta.get("effective_end_text") or "N/A"
                    lines.append(f"     â±ï¸ {s_text} ~ {e_text} ({basis})")
            lines.append("")

        # æ·»åŠ å…³ç³»ç»“æžœ
        if relations:
            lines.append("ðŸ”— åŒ¹é…çš„å…³ç³»ï¼š")
            for i, result in enumerate(relations, 1):
                score_pct = result.score * 100
                subject = result.metadata.get("subject", "")
                predicate = result.metadata.get("predicate", "")
                obj = result.metadata.get("object", "")
                lines.append(f"  {i}. [{score_pct:.1f}%] {subject} {predicate} {obj}")
                time_meta = result.metadata.get("time_meta", {})
                if time_meta:
                    basis = time_meta.get("match_basis", "none")
                    s_text = time_meta.get("effective_start_text") or "N/A"
                    e_text = time_meta.get("effective_end_text") or "N/A"
                    lines.append(f"     â±ï¸ {s_text} ~ {e_text} ({basis})")
            lines.append("")

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        lines.append(f"ðŸ“Š ç»Ÿè®¡: å…±{len(results)}æ¡ç»“æžœï¼ˆæ®µè½: {len(paragraphs)}, å…³ç³»: {len(relations)}ï¼‰")

        return "\n".join(lines)

    async def search_batch(
        self,
        queries: List[str],
        top_k: int = 10,
    ) -> Dict[str, List[Any]]:
        """æ‰¹é‡æ£€ç´¢çŸ¥è¯†

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›žçš„ç»“æžœæ•°

        Returns:
            æŸ¥è¯¢åˆ°ç»“æžœçš„æ˜ å°„ {query: results}
        """
        if not self.retriever:
            logger.error(f"{self.log_prefix} æ£€ç´¢å™¨æœªåˆå§‹åŒ–")
            return {}

        results_map = {}

        for query in queries:
            try:
                results = self.retriever.retrieve(query, top_k=top_k)
                results_map[query] = results
                logger.info(
                    f"{self.log_prefix} æ‰¹é‡æ£€ç´¢: '{query}' -> {len(results)}æ¡ç»“æžœ"
                )
            except Exception as e:
                logger.error(f"{self.log_prefix} æ‰¹é‡æ£€ç´¢å¤±è´¥ '{query}': {e}")
                results_map[query] = []

        return results_map

    def get_statistics(self) -> Dict[str, Any]:
        """èŽ·å–æ£€ç´¢ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.retriever:
            return {
                "status": "not_initialized",
            }

        stats = {
            "status": "active",
            "config": {
                "top_k_paragraphs": self.retriever.config.top_k_paragraphs,
                "top_k_relations": self.retriever.config.top_k_relations,
                "alpha": self.retriever.config.alpha,
                "enable_ppr": self.retriever.config.enable_ppr,
                "enable_parallel": self.retriever.config.enable_parallel,
                "retrieval_strategy": self.retriever.config.retrieval_strategy.value,
            },
        }

        # æ·»åŠ å­˜å‚¨ç»Ÿè®¡
        if hasattr(self.retriever, "vector_store"):
            stats["vector_store"] = {
                "num_vectors": self.retriever.vector_store.num_vectors,
                "dimension": self.retriever.vector_store.dimension,
            }

        if hasattr(self.retriever, "graph_store"):
            stats["graph_store"] = {
                "num_nodes": self.retriever.graph_store.num_nodes,
                "num_edges": self.retriever.graph_store.num_edges,
            }

        return stats

    def __repr__(self) -> str:
        return (
            f"KnowledgeSearchAction("
            f"retriever_initialized={self.retriever is not None})"
        )
